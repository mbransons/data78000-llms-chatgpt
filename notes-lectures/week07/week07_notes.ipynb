{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression recap\n",
    "\n",
    "* Supervised learning\n",
    "* Classification model\n",
    "* Uses feature weights to generate predictions about and example\n",
    "* feature * weight transformes into a probability with activation function\n",
    "* Threshold for activation determines\n",
    "\n",
    "## multinomial classification\n",
    "* Each label/class has its own weight set (works for my end of the world generator)\n",
    "* \n",
    "\n",
    "## Logistic Regression vs. Neural Network\n",
    "* manual threshold vs. threshold learned from training\n",
    "* Sigmoid vs. ReLu\n",
    "* both do binomial or multinomial output\n",
    "* single architectural variation vs. many architectural variations\n",
    "* single training mechanism vs. multiple, layered training mechanisms\n",
    "* output = output vs. output often further manipulated (messing with the probabilities is possible through further manipulation)\n",
    "\n",
    "## perceptron\n",
    "* same as a single node logistic regression (features, weights, activation function, output)\n",
    "\n",
    "## neural networks\n",
    "* each input feature is connected to a \"hidden layer\" connecting all feature weights to all activation function some nodes are activated, others are not\n",
    "* only the activated nodes of the \"hidden layer\" are passed on to the activation function of the output layer\n",
    "* \n",
    "\n",
    "## Sum of the features times the weights and then the activation function and then the output fires or not...\n",
    "\n",
    "## However many hidden layers, is however many layers of abstraction, tracing every single weight back through the layers is so complex we can't define exactly what's happening in each layer\n",
    "\n",
    "## a specific node doesn't truly learn anything content-wise, only the randomness the weight is updated...\n",
    "\n",
    "## building the Klingon Cookbook\n",
    "\n",
    "## there is no sanctuary!!! (no ground truth, forward and back through the forward training and back propogation). This is an EPOCH\n",
    "\n",
    "## so many layers\n",
    "* the layers of abstraction, consolidates more information\n",
    "* leveraging more contextual information\n",
    "* trained many times to continually refine itself\n",
    "\n",
    "## how does the neural network learn???\n",
    "* tuning weights over and over\n",
    "* ML lives in the train/test paradigm. \n",
    "* some data is used to train, some used to test\n",
    "* accuracy is the % correct\n",
    "\n",
    "## fit don't overfit\n",
    "* overfit means it's not really doing anything do,\n",
    "* train too long, with too many iterations, or too little data leads to overfittting and a useless model\n",
    "\n",
    "## cost function\n",
    "* loss is the difference between real values and predicted values\n",
    "* average of the losses\n",
    "\n",
    "## gradient descent\n",
    "* building a better pachinko machine that gets the best prize most of time...\n",
    "\n",
    "## back propogation\n",
    "* an EPOCH\n",
    "\n",
    "## three types of NN's (not comprehensive)\n",
    "* Chat GPT is likely a bunch of models taped together\n",
    "* feedforward (OCR good example)\n",
    "* Recurrent\n",
    "* Transformers (encoder - decoder models) - train your sentences in both directions\n",
    "    * uses masked words and asked the encoder to predicted that word in context. Tuning weights is based on prediction of the masked words.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
