{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "\n",
    "* Collab needs to use T4 or TPU for processing\n",
    "* Testing Pythia Prompts - Use list of names to loop a tokenizer through that list with a constructed string with the name. Saving all the data in a Pandas dataframe\n",
    "\n",
    "#### Foundation Model\n",
    "\n",
    "* a transformer model, GPT-3, GPT-4, Pythia, LLaMa 2\n",
    "    * Pythia \n",
    "        * models vary in size by the number of 'weights' The work from the same size training data, but different models use more and more hidden layers in the model producing weights between 70M to 12B.\n",
    "        * The Pythia models get less biased as the number of weights increases\n",
    "    * LLaMa 2 \n",
    "        * is an open-sourced LLM that can be finetuned on any laptop\n",
    "        * 7B, 13B, 70B\n",
    "        * Three pre-fine tuned models (Chat and Code)\n",
    "\n",
    "#### \"Chat\" Model & other Finetuned models\n",
    "\n",
    "* Chat-GPT that is tuned for a very specific purpose\n",
    "* Reduce bias\n",
    "* Task specification\n",
    "* Domain specification\n",
    "* modifying the weights within the layers of the model, changing the model by exposing it to new data and training it for a few epochs.\n",
    "* though the changes are relatively small, infintesimally small relative the model's number of weights, the results can be noticeable.\n",
    "* Finetuning is like a form of manipulating the past to change the future. As the model is slightly tweeked, after each epoch there are noticeable results.\n",
    "* BERT first finetuned only at the end, adding a new layer at the end modifying the output\n",
    "    * Then experiments were made finetuning the entire model's hidden layers, but it was discovered that it wasn't that necessariy as it was basically the same as freezing the first 8 layers, and then only retraining the last four layers.\n",
    "\n",
    "#### Prompt engineering & hyperparameters\n",
    "\n",
    "* On top of tailoring prompts, add specific tuning tools like 'temperature' in ChatGPT\n",
    "\n",
    "#### RAG\n",
    "\n",
    "* The DB that is queried is actually a vectorized version of the DB, similar to a gLove model\n",
    "* The prompt is also a vector that finds the most proximate vector in the DB\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetitive lines removed and saved to day-3-fixed.txt\n"
     ]
    }
   ],
   "source": [
    "unique_lines = set()\n",
    "def remove_repetitive_lines(input_file, output_file):\n",
    "    with open(input_file, 'r') as input_f:\n",
    "        for line in input_f:\n",
    "            line = line.strip()\n",
    "            if line not in unique_lines:\n",
    "                unique_lines.add(line)\n",
    "\n",
    "    with open(output_file, 'w') as output_f:\n",
    "        for line in unique_lines:\n",
    "            output_f.write(line + '\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"day-3.txt\"  # Replace with the path to your input file\n",
    "    output_file = \"day-3-fixed.txt\"  # Replace with the desired output file name\n",
    "\n",
    "    remove_repetitive_lines(input_file, output_file)\n",
    "    print(\"Repetitive lines removed and saved to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\n",
      "\n",
      "3\n",
      "seems like we've had\n",
      "4\n",
      "\n",
      "5\n",
      "seems like we've had\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "seems like we've had\n",
      "9\n",
      "a temporary outage\n",
      "10\n",
      "\n",
      "11\n",
      "a temporary outage\n",
      "12\n",
      "\n",
      "13\n",
      "\n",
      "14\n",
      "a temporary outage\n",
      "15\n",
      "and there may be\n",
      "16\n",
      "\n",
      "17\n",
      "and there may be\n",
      "18\n",
      "\n",
      "19\n",
      "\n",
      "20\n",
      "and there may be\n",
      "21\n",
      "and with that i end day three ds-106\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "file = open('day-4.txt', 'r')\n",
    "un_lines = set()\n",
    "n = 1\n",
    "for line in file:\n",
    "    line = line.strip()\n",
    "    n = n + 1\n",
    "    print(line)\n",
    "    print(n)\n",
    "    if line not in un_lines:\n",
    "        un_lines.add(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'a temporary outage',\n",
       " 'and there may be',\n",
       " 'and with that i end day three ds-106',\n",
       " \"seems like we've had\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetitive lines removed while maintaining the order and saved to day-3-fixed.txt\n"
     ]
    }
   ],
   "source": [
    "def remove_repeated_lines(input_file, output_file):\n",
    "    unique_lines = []\n",
    "    seen_lines = set()\n",
    "\n",
    "    with open(input_file, 'r') as input_f:\n",
    "        for line in input_f:\n",
    "            line = line.strip()\n",
    "            if line not in seen_lines:\n",
    "                seen_lines.add(line)\n",
    "                unique_lines.append(line)\n",
    "\n",
    "    with open(output_file, 'w') as output_f:\n",
    "        for line in unique_lines:\n",
    "            output_f.write(line + '\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"day-3.txt\"  # Replace with the path to your input file\n",
    "    output_file = \"day-3-fixed.txt\"  # Replace with the desired output file name\n",
    "\n",
    "    remove_repeated_lines(input_file, output_file)\n",
    "    print(\"Repetitive lines removed while maintaining the order and saved to\", output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
